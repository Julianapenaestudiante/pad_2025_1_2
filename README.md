# Scraping de Datos HistÃ³ricos del PetrÃ³leo WTI (`CL=F`) desde Yahoo Finance

Este proyecto implementa una soluciÃ³n automatizada de scraping para recolectar datos histÃ³ricos del precio del petrÃ³leo WTI (West Texas Intermediate) desde [Yahoo Finance](https://es.finance.yahoo.com/quote/CL=F/history/). El objetivo principal es extraer la tabla de cotizaciones histÃ³ricas y almacenarlas en formato CSV o Excel para anÃ¡lisis posterior.

## ğŸ›  TecnologÃ­as y Bibliotecas Utilizadas

- Python 3.10+
- `requests` - Para hacer solicitudes HTTP a la pÃ¡gina web.
- `BeautifulSoup` - Para analizar el contenido HTML y extraer la tabla de datos.
- `pandas` - Para estructurar y exportar los datos.
- GitHub Actions - Para integraciÃ³n continua.

## ğŸ“ Estructura del Proyecto

```
pad_2025_1_2/
â”œâ”€â”€ .github/workflows/python-app.yml       # Flujo de trabajo para CI
â”œâ”€â”€ docs/evidencia_scraping.md             # Evidencia del proceso
â”œâ”€â”€ src/edu_pad/
â”‚   â”œâ”€â”€ __init__.py                        # Inicializador del mÃ³dulo
â”‚   â”œâ”€â”€ dataweb.py                         # Clase para scraping
â”‚   â””â”€â”€ main.py                            # Script principal
â”œâ”€â”€ data_web.csv                           # Archivo generado con los datos
â”œâ”€â”€ dataweb_limpio.xlsx                    # Datos limpios para anÃ¡lisis
â”œâ”€â”€ README.md                              # Este archivo
â”œâ”€â”€ requirements.txt                       # LibrerÃ­as necesarias
â””â”€â”€ setup.py                               # ConfiguraciÃ³n del paquete
```

## ğŸš€ Â¿CÃ³mo Ejecutar el Proyecto?

1. Clonar el repositorio:
   ```bash
   git clone https://github.com/Julianapenaestudiante/pad_2025_1_2.git
   cd pad_2025_1_2
   ```

2. Crear un entorno virtual (opcional pero recomendado):
   ```bash
   python -m venv venv
   source venv/bin/activate  # En Windows: venv\Scripts\activate
   ```

3. Activa el entorno virtual:
   ```bash
   venv\Scripts\activate
   ```

4. instala dependencias:
   ```bash
   pip install -e .
   ```

5. Ejecutar el script principal:
   ```bash
   python src/edu_pad/main.py
   ```

   
## ğŸ³ Â¿CÃ³mo Ejecutar el Proyecto con Docker?

Esta es la forma mÃ¡s rÃ¡pida y recomendada para ejecutar el proyecto sin necesidad de instalar dependencias manualmente.

### 1. Descargar la imagen

```bash
docker pull julimaria44/pad_2025_1_2:latest
```

Esto descargarÃ¡ la versiÃ³n mÃ¡s reciente del proyecto desde Docker Hub.

### 2. Ejecutar el contenedor

```bash
docker run julimaria44/pad_2025_1_2:latest
```

Esto iniciarÃ¡ el contenedor y ejecutarÃ¡ automÃ¡ticamente el mÃ³dulo `main.py`, generando el archivo `data_web.csv` dentro del contenedor.

### 3. (Opcional) Guardar el archivo CSV localmente

```bash
docker run --rm -v "$(pwd)/csv_output:/app/static/csv" julimaria44/pad_2025_1_2:latest
```

Este comando vincula la carpeta local `csv_output` con el directorio donde el contenedor guarda el archivo CSV, para que puedas acceder a Ã©l desde tu mÃ¡quina.

---

## ğŸ“„ DescripciÃ³n de Archivos Principales

- `dataweb.py`: Contiene la lÃ³gica de scraping con `requests` y `BeautifulSoup`.
- `main.py`: Ejecuta el scraper y guarda los datos en `data_web.csv`.
- `data_web.csv`: Resultado crudo extraÃ­do desde Yahoo Finance.
- `dataweb_limpio.xlsx`: VersiÃ³n depurada del conjunto de datos para anÃ¡lisis.

## ğŸ§  Autor

- Juliana Maria PeÃ±a Suarez

## ğŸ“œ Licencia

Este proyecto es solo para fines acadÃ©micos y educativos.
